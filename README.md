
# AI-Alignment-Project

## Introduction

This repository contains a suite of AI models designed to evaluate and align text data across various dimensions, including toxicity, bias, and fairness. Our goal is to promote the development of more ethical, unbiased, and equitable AI systems by providing tools to assess and mitigate harmful content in text data.

## Features
- **Toxicity Detection:** Identify and quantify toxic content in text to foster healthier online interactions.
- **Bias Assessment:** Evaluate text for biased language to ensure fair and equitable AI treatments.
- **Fairness Metrics:** Implement fairness metrics to audit AI models for discriminatory behaviors.

## Demos

- **Fairness Evaluation:**
  - Data Perturbation Demo: 
    [![Open In Colab](https://img.shields.io/badge/Data%20Perturbation-Open%20In%20Colab-yellow?style=for-the-badge&logo=googlecolab&labelColor=555555)](https://colab.research.google.com/drive/1qVCu62v1NDAFMwuHijJR_hSY8NhIVK9d?usp=sharing)

  - Fairness Evaluation Demo:
    [![Open In Colab](https://img.shields.io/badge/Fairness%20Evaluation-Open%20In%20Colab-green?style=for-the-badge&logo=googlecolab&labelColor=555555)](https://colab.research.google.com/drive/13OwZqz_wZNgc4O9uCqewwKP5QBRSSVLp?usp=sharing)


### Usage
Refer to individual model directories for specific usage instructions. Typically, you can run a model using:

## Getting Started
To get started with our AI alignment models, follow these steps:

### Prerequisites
- Python 3.9+
- recommended: pytorch with cuda

### Installation
1. Clone the repository:

2. Install required packages: pip install -r requirements.txt

## Models
- **Bias Detection Model:** The link to the model is D1V1DE/bias-detection on huggingface. A DistillRoBERTa bias classification model fine-tuned from valurank/distilroberta-bias. MBIC dataset is used as training data.
- **Model 2:** Description and purpose.
- **Model 3:** Description and purpose.

## License
This project is licensed under the Apache 2.0 License - see the [LICENSE](LICENSE) file for details.


## Acknowledgments
- Acknowledge any contributors, funding sources, or inspirational projects here.

## Contact
For questions or feedback, please open an issue in the repository or contact us directly at `ldvdzhang@gmail.com`.

Thank you for exploring our AI Alignment Model!

   
